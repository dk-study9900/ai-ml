[Faculty (Olympus)] 11:24:00
Data science is equal to information science plus decision science. Decisions that you will make just taking data without having any discussions with the stakeholders And plugging that data into an algorithm, that is not data science.

[Faculty (Olympus)] 11:24:12
And just keep talking with your stakeholders, not having meaningful data not refining data, not cleansing data, not understanding what an algorithm does behind the scenes.

[Faculty (Olympus)] 11:24:23
That is also not data science. So data science is a combination of better on doing machine learning or deep learning or generative AI.

[Faculty (Olympus)] 11:24:32
Am I enabling? First, am I solving for the right thing? Does the business know what value will be generated?

[Faculty (Olympus)] 11:24:40
Too. Is the business solving for the right thing. In your careers, most of the times the teams will come to you and they'll say, well, we have this problem. Let's use AI to solve it.

[Faculty (Olympus)] 11:24:49
It's your responsibility being a data scientist and a decision scientist to drive that clarity for your stakeholders whether or not it is a good, AI would be a good application for their problem, right?

[Faculty (Olympus)] 11:25:05
So data science is equal to information science plus decision science. It's enabling All of these things, practically getting the right data problem solving or not problem solving, problem refinement refining the problem with your business stakeholders Because data science solutions are time intensive and cost intensive, whether you're doing machine learning, deep learning, or generative AI.

[Faculty (Olympus)] 11:25:31
For example, in my company right now when we train a custom GPT for any of our business teams.

[Faculty (Olympus)] 11:25:37
They have to prove value. The company has defined a formula, what kind of value they want to see before they even give anyone a license because licensing costs money.

[Faculty (Olympus)] 11:25:49
So make sure you answer all of these questions and as you progress in your journeys as a data scientist in this program.

[Faculty (Olympus)] 11:25:57
Constantly think I'm also becoming a decision scientist. The information, I have to make the best use of the information.

[Faculty (Olympus)] 11:26:06
I have to enable my stakeholders to use this information in the best way possible.

[Faculty (Olympus)] 11:26:10
So I'm not only becoming a data scientist, I'm also becoming a decision scientist.

[Faculty (Olympus)] 11:26:16
And information scientist. Okay, so I hope that answers your question.

[Faculty (Olympus)] 11:26:22
So this slide speaks about the artificial intelligence. And to give you guys a flavor of some of the things that some of us or all of us may have experienced in their real life.

[Faculty (Olympus)] 11:26:33
Patent recognition. If you enable face ID for your Bank of America account.

[Faculty (Olympus)] 11:26:40
Or your face ID for your cell phones, it will not allow you to unlock your phone if it doesn't recognize your face.

[Faculty (Olympus)] 11:26:48
So fun fact, excuse me, over Halloween, I was dressed up as something And I had stuff on my face and I was trying to unlock my phone and my phone failed to recognize me, even though it was me, it was my face.

[Faculty (Olympus)] 11:27:03
However, it was not the pattern. That it had studied stored in its memory.

[Faculty (Olympus)] 11:27:09
Self-driving cars, application of computer vision, very, very powerful application, actually. So we've all experienced that. These cars are trained on not just one kind of data.

[Faculty (Olympus)] 11:27:23
They are trained on enormous volumes of data so think about What does a self-driving car need?

[Faculty (Olympus)] 11:27:29
To successfully and safely drive on the road.

[Faculty (Olympus)] 11:27:35
It doesn't just need to know I have to drive forward.

[Faculty (Olympus)] 11:27:38
It needs to know the weather conditions. It needs to know if somebody is crossing the road.

[Faculty (Olympus)] 11:27:45
Is it somebody like me crossing the road or is somebody on wheelchair crossing the road? Because what happens if I'm crossing the road or you are crossing the road and you see a car speeding towards you, right? You will spring to action.

[Faculty (Olympus)] 11:27:59
That won't be a case for a woman who's using a walker to cross the street or who's on a wheelchair.

[Faculty (Olympus)] 11:28:05
So self-driving cars have studied all of these different images, patterns, conditions, weather.

[Faculty (Olympus)] 11:28:13
The road conditions, the foliage around the around the roads and you name it.

[Faculty (Olympus)] 11:28:19
So that is a very powerful application of AI. Face recognition or pattern recognition, almost overlapping chat bots.

[Faculty (Olympus)] 11:28:27
These days, and I kind of miss the human touch, but these days you cannot get to a human person or a human assistant Without spending 20 minutes with a chat bot. If you're lucky, you'll get to a human assistant, right?

[Faculty (Olympus)] 11:28:40
So Amazon has chatbots enabled. Everyone has chatbots enabled. So that is a classic application.

[Faculty (Olympus)] 11:28:45
And sentiment analysis. What kind of sentiment analysis do you think this could be?

[Faculty (Olympus)] 11:28:52
I'm going to look in the chat window.

[Faculty (Olympus)] 11:28:59
What comes to mind? Priya, yes, I will explain neural networks in the upcoming slides.

[Faculty (Olympus)] 11:29:08
Customer reviews, yes. What are people saying about my service? Is my enterprise support doing a good job? Yes.

[Faculty (Olympus)] 11:29:17
But their customer reviews positive or not, absolutely. Ticketing management, yes, how many tickets were logged in, Arun, as critical or of low priority or medium priority, right? So sentiment analysis has wide variety of applications. You could analyze customer reviews.

[Faculty (Olympus)] 11:29:33
You could analyze sentiments from social media about a political campaign, a religious sentiment.

[Faculty (Olympus)] 11:29:40
You could analyze sentiments or views on a movie on a new product launch.

[Faculty (Olympus)] 11:29:45
So also very, very powerful application. Thank you for the input that autonomous surgery is present twice. I will let the program know about that.

[Faculty (Olympus)] 11:29:55
Thank you for highlighting that. Language translation. That is one of the biggest applications that I'm seeing in my workplace so think about having a legal document that's given to you in Portuguese.

[Faculty (Olympus)] 11:30:10
And the compliance team has to translate that language. So before, there were hundreds and thousands of dollars that were being paid to professionals who would just do that for you.

[Faculty (Olympus)] 11:30:20
Who would just translate something for you from one language to the other language.

[Faculty (Olympus)] 11:30:26
However, because of generative AI capabilities, now we can translate English to Portuguese, Spanish, Arabic, and you name it.

[Faculty (Olympus)] 11:30:34
Clinical trial optimization, robotics, autonomous surgery, all of these are very very powerful applications of AI.

[Faculty (Olympus)] 11:30:44
Any other applications that you guys can think of? That are not on this slide. I'd be curious to know that.

[Faculty (Olympus)] 11:30:50
Please put in the chat.

[Faculty (Olympus)] 11:30:55
Day-to-day life applications of AI.

[Faculty (Olympus)] 11:31:01
Coding, graphic design.

[Faculty (Olympus)] 11:31:09
Yeah. Recommendation systems. Yes. Netflix is heavy on recommendation systems based on what you've watched in the past.

[Faculty (Olympus)] 11:31:18
Virtual assistants, excellent. Based on what you've watched in the past, recommendation systems will say, oh, okay, this guy likes to watch sci-fi movies, so I will recommend a similar content.

[Faculty (Olympus)] 11:31:30
Amazon does that too. I… I barely have to type anymore like what i'm looking for based on my past purchase history, it automatically detects what is it that I might be looking for or presents me with a very vast variety of similar choices, right?

[Faculty (Olympus)] 11:31:48
Active security system predicting the sales? Yes. All of these are all of these are very very uh very very real life and powerful applications of AI.

[Faculty (Olympus)] 11:32:01
Okay. So moving on. So let's talk about machine learning in a little bit more depth.

[Faculty (Olympus)] 11:32:09
So you have to train a model. As a data scientist, the business team comes to you and they say, hey.

[Faculty (Olympus)] 11:32:15
Suresh, I have to train a model. And you will say, oh, and the client says, or the business team says, well, tell me how does my model work?

[Faculty (Olympus)] 11:32:25
And serration, almost every single person on this call after today will be equipped to tell them well your model for me to be able to solve your problem, I would need data.

[Faculty (Olympus)] 11:32:37
It has to be structured data. It has to be labeled data.

[Faculty (Olympus)] 11:32:42
Based on that structure of label data, your model will learn from the patterns what has happened in the past. Past could be six months past could be two years, three years, could be any duration.

[Faculty (Olympus)] 11:32:55
And based on that, the model will help us predict or classify things.

[Faculty (Olympus)] 11:32:59
Okay, so this is what we tell business when they come to us saying.

[Faculty (Olympus)] 11:33:03
How does the model work? But before we come here we must talk data.

[Faculty (Olympus)] 11:33:11
Never, ever commit. And keep this in mind. Never.

[Faculty (Olympus)] 11:33:17
In your life as a data scientist. Get excited when somebody comes to you. Oh, I have a problem. Let's use a machine learning.

[Faculty (Olympus)] 11:33:26
Model to or put a machine learning model to work Always think training data. What do you have? Show me.

[Faculty (Olympus)] 11:33:34
Show me what you got. Where's the data? Data in real life is messy. It's noisy. It has outliers. It has missing values.

[Faculty (Olympus)] 11:33:42
Study the data. Understand the data, discuss it with business And once you have spent enough time 30 to 40% of your time here in understanding and befriending your data Only then come to this stage.

[Faculty (Olympus)] 11:34:01
I speak from experience. I have my master's, I have my MBA and then my second master's is in data science and business analytics.

[Faculty (Olympus)] 11:34:12
As a new data scientist about seven, eight years ago, I was like, okay, let's do this. Anytime the business team would come to me.

[Faculty (Olympus)] 11:34:20
But I pretty soon realized that how fast I was falling flat on the floor with that approach.

[Faculty (Olympus)] 11:34:27
You cannot jump to training a model unless you have sat down with the business team. So I learned the hard way, right? And you guys won't because you guys know you must, must, must befriend the data, befriend your stakeholders.

[Faculty (Olympus)] 11:34:40
Ask them how much data do you have? Sometimes the problem they're solving, six months of data is enough.

[Faculty (Olympus)] 11:34:48
Sometimes you need more data. So how much data is enough?

[Faculty (Olympus)] 11:34:54
The industry standard is it has to be at least 10 times of the features which is columns the number of rows has to be 10 times the number of columns in your data set or 30 times for the number of columns in your data set.

[Faculty (Olympus)] 11:35:13
When to choose 10 over 30? That depends on what exactly you're trying to solve for, right?

[Faculty (Olympus)] 11:35:20
More data. Is not always better. It's an intuitive thing. More is always better.

[Faculty (Olympus)] 11:35:26
It's not. In fact, we will learn here in the upcoming slides that sometimes when we get tons of data.

[Faculty (Olympus)] 11:35:32
We do dimensionality reduction. There's 500 columns, I will never put all 500 columns into into my model because I must understand with my business stakeholders Which of those 500 columns are meaningful? Which of those 500 columns are actually driving the process?

[Faculty (Olympus)] 11:35:51
Or mean something to the process. Right? Why the process?

[Faculty (Olympus)] 11:35:57
Because this guy here This model here, it is getting trained on an underlying process.

[Faculty (Olympus)] 11:36:07
Or an underlying demographic. Right? For example, if I'm trying to predict what will be the price of a barrel of oil.

[Faculty (Olympus)] 11:36:17
In the next year. It's getting trained on that underlying process, on that underlying market condition.

[Faculty (Olympus)] 11:36:25
If I'm trying to classify Well, my customer buy this new product from me or not. I am still training it in that underlying customer demographic, the underlying customer profile.

[Faculty (Olympus)] 11:36:38
So your machine learning models, while highly numerical and statistical in nature, they're actually trying to study and address a real life problem in the world.

[Faculty (Olympus)] 11:36:50
And that real life problem is learned by them from the training data.

[Faculty (Olympus)] 11:36:56
So sometimes more is not better. So be very mindful of that.

[Faculty (Olympus)] 11:37:01
Also, you have to be mindful when you're thinking about training data. And remember, we're spending 30 to 40, maybe 50% of our time in understanding data, befriending your data, right?

[Faculty (Olympus)] 11:37:10
So is the data relevant? And what does that mean?

[Faculty (Olympus)] 11:37:16
So if we have, can I use COVID data to predict the house pricing these days?

[Faculty (Olympus)] 11:37:22
Because when we were doing COVID, In times of COVID, the house prices were like way up.

[Faculty (Olympus)] 11:37:30
More people were working from home. More people were wanting to invest in a better better house, better working conditions from home. So that data is not applicable now. If it's my neighborhood today.

[Faculty (Olympus)] 11:37:46
Yes, Harry, that data is an outlier in today's term, but it was not an outlier.

[Faculty (Olympus)] 11:37:54
A couple of years ago it was very or highly relevant data so always Always be very mindful that the data that the business is giving to you how relevant it is.

[Faculty (Olympus)] 11:38:09
Don't trust the business. With that information.

[Faculty (Olympus)] 11:38:13
Be smart, be wise, be on top of things and ask Ask them questions, probing questions. How relevant is it? If it's a supply chain problem, are you still dealing with the same vendors? Are you still dealing with the same shipment? Are you still dealing with the same packaging and procurement teams? How relevant?

[Faculty (Olympus)] 11:38:32
Is this data. Sometimes business, actually not sometimes, you know, to be honest, most of the times business processes change, but businesses don't change the way they are collecting data.

[Faculty (Olympus)] 11:38:44
So we have to be mindful as responsible data scientists. How relevant is my data? So COVID data such as data from WARS, Or if there is an older If an area of the world, let's imagine there is an area of the world that has a lot of older people and they were buying certain products, right?

[Faculty (Olympus)] 11:39:03
And as older people pass away and newer, younger people start to inhabit that same area, the same products are not going to sell anymore that effectively.

[Faculty (Olympus)] 11:39:13
So the underlying demographic, the process or the demographic this guy was trying to study has now changed.

[Faculty (Olympus)] 11:39:20
So always talk how much data And how relevant is that data?

[Faculty (Olympus)] 11:39:28
And sometimes we have to go to get external data. If you're a client or company is willing to pay for it.

[Faculty (Olympus)] 11:39:34
They will pay for external data. And other times we have to wait to get that, right?

[Faculty (Olympus)] 11:39:40
And then lastly. The data you get, like I mentioned before.

[Faculty (Olympus)] 11:39:46
Is never. Going to be in optimal condition.

[Faculty (Olympus)] 11:39:49
We don't get the data from client and just bring it right here.

[Faculty (Olympus)] 11:39:53
The model. We spent significant amount of time after we have understood the data with our stakeholders in cleaning the data. It's called data wrangling or exploratory data analysis, right? You will study that in your initial modules.

[Faculty (Olympus)] 11:40:09
So we clean the data for missing values. Your data sets are going to have missing values. Your data sets are going to have outliers.

[Faculty (Olympus)] 11:40:16
What are outliers? If it's age data, let's say. Let's say we have age ranges in our data set from 18 to 60.

[Faculty (Olympus)] 11:40:27
And suddenly two values have age 88 and 92. What should we do? Just take the data as is.

[Faculty (Olympus)] 11:40:35
If you see an outlier like that, you must pause. And investigate. Is that a normal outlier?

[Faculty (Olympus)] 11:40:45
Yes. Ashish to learn all the patterns in the data, is it not a good idea to consult with a subject matter expert? Exactly. That's what I'm speaking to right now.

[Faculty (Olympus)] 11:40:56
When you see an outlier, go back to your business team.

[Faculty (Olympus)] 11:41:00
Ask them this 88 and 92 year age that I'm seeing here, is that normal noise?

[Faculty (Olympus)] 11:41:06
Or is that special noise. Do I need to remove it was it human error. Data is collected and stored by either humans and machines.

[Faculty (Olympus)] 11:41:16
And both make mistakes. We make mistakes and machines make mistakes, right?

[Faculty (Olympus)] 11:41:22
So Renuga says social security number data with humans over 360.

[Faculty (Olympus)] 11:41:29
Yes. So outliers, right? So go back to your business teams. Even if your data set has missing values.

[Faculty (Olympus)] 11:41:35
And remember, you're still here. You haven't even come here yet.

[Faculty (Olympus)] 11:41:41
If your data set has missing values, you must, like Ashish is asking, you must go back to the subject matter expert or the business team Ask them. There are 500 missing values.

[Faculty (Olympus)] 11:41:54
Do you want me to drop them? Or do you want me to replace those values?

[Faculty (Olympus)] 11:42:01
With something and how to impute for missing values, that is something that you will learn in your program, how to address missing values. So you could do mean imputation, mode imputation, median imputation, all of these have their own special use cases.

[Faculty (Olympus)] 11:42:15
But you don't make these decisions You make these decisions going back to the business team and going back to the subject matter expert.

[Faculty (Olympus)] 11:42:26
Only when you've done all of these things on training data you come over here.

[Faculty (Olympus)] 11:42:33
So what happens when you come over here? Let's take a look.

[Faculty (Olympus)] 11:42:40
So you've spent a good amount of time Right here. And now you're training a model When we train a model, our models have, how do we know? Actually, let me ask you guys, how do you know your model is

[Faculty (Olympus)] 11:42:55
Good. I'm looking at the chat window right now. How do you know when you have trained a model I just want to you guys, there is no right answer at this stage I just want to check where everybody's mind is based on the outcomes.

[Faculty (Olympus)] 11:43:12
Okay, run a sample test. Okay. Close enough. All right, fair enough.

[Faculty (Olympus)] 11:43:18
Fair enough. So I get the idea where the level of understanding is okay So when we train a model, we measure the predictive performance of the model.

[Faculty (Olympus)] 11:43:28
Right? If the subject matter expert conquers, I'm going to come back to that point in a minute.

[Faculty (Olympus)] 11:43:34
So we've done our due diligence here. We've done the data cleansing, data wrangling. Data is good enough.

[Faculty (Olympus)] 11:43:41
Thumbs up from business team. Now we're training a model. You're training a model as a data scientist and you have trained a model, but how good is good enough, right?

[Faculty (Olympus)] 11:43:50
So we measure the predictive performance of our model. And then in general terms, it's called accuracy. But then we have other metrics such as recall and precision and you will learn all of these in your upcoming sessions. You will be pros in that.

[Faculty (Olympus)] 11:44:10
But we have these metrics to assess how good our model is performing.

[Faculty (Olympus)] 11:44:16
Is 60% good enough? So let's say I'm going to ask you a question here.

[Faculty (Olympus)] 11:44:21
If I am training a model And I'm your data scientist and all of you guys on this call today are my business team.

[Faculty (Olympus)] 11:44:30
I am training a model to detect whether or not somebody will have cancer.

[Faculty (Olympus)] 11:44:37
What do you think the predictive performance of that model be like?

[Faculty (Olympus)] 11:44:41
60% good enough? Or 95% good enough.

[Faculty (Olympus)] 11:44:47
I'm looking at chat right now. 95, 95.

[Faculty (Olympus)] 11:44:53
Do you think higher would be better? Should we stop at 95?

[Faculty (Olympus)] 11:44:59
Absolutely. So whoever rode highest yes So this is the kind of problem trying to predict whether or not somebody has cancer And my model is only telling me that accurately 60% of the time, which means the other 40% of the times the model might not detect

[Faculty (Olympus)] 11:45:22
That someone may have cancer and it may detect that it doesn't or classify that the person does not have cancer.

[Faculty (Olympus)] 11:45:29
Think of the consequences. What are the consequences for that misclassification?

[Faculty (Olympus)] 11:45:35
So for this kind of problem where you're trying to predict some terminal disease.

[Faculty (Olympus)] 11:45:40
The predictive performance or accuracy, and there are other terms, precision and recall, you will learn them very, very thoroughly in your upcoming classes.

[Faculty (Olympus)] 11:45:52
We want higher. Yes. So Joshua, the false negatives and positives I want to hold off to that. That speaks to that speaks to precision and recall, right?

[Faculty (Olympus)] 11:46:04
So in recall, the higher the recall, the lesser are false negatives are, right?

[Faculty (Olympus)] 11:46:12
You don't want to be not identified as not having cancer where you have cancer.

[Faculty (Olympus)] 11:46:20
Right. So yeah, I won't speak in detail to that because you guys will study that concept in your upcoming classes. But if you want to talk in detail about that, precision and recall and false negative and false positive. I'll stay on after the session and we'll chat deeper on that.

[Faculty (Olympus)] 11:46:35
So what I'm trying to address You've started here.

[Faculty (Olympus)] 11:46:41
You've trained a model and now you're predicting, but how good is your prediction depends on what you're trying to solve for. So for cancer detection, if I'm trying to detect that somebody is going to be a terrorist or not. I cannot.

[Faculty (Olympus)] 11:46:56
I cannot live with 60% accuracy, right? Let's imagine another scenario where we want to predict There is a product coming out in a product coming out 18 months.

[Faculty (Olympus)] 11:47:12
It's not even launched yet. But I'm your data scientist. You guys are my business team. And I say, hey, I got the model at 75% accuracy.

[Faculty (Olympus)] 11:47:24
And we're still in testing phase. Would that be good enough for you? What do you guys think?

[Faculty (Olympus)] 11:47:36
No, maybe yes. Okay. So always higher the better.

[Faculty (Olympus)] 11:47:42
Okay, that's one thing. But keep in mind.

[Faculty (Olympus)] 11:47:47
Higher the better also means More data.

[Faculty (Olympus)] 11:47:52
So there is no right or wrong pathing. Depends on the training. How much data do you have?

[Faculty (Olympus)] 11:47:59
How much runway do you have to deployment? Ken, you're right on yes Dinesh Kumar depends on the goal of the project. Absolutely. All of these are exactly right questions.

[Faculty (Olympus)] 11:48:11
So how good is good enough? I'm saying that again and again.

[Faculty (Olympus)] 11:48:14
Because in some cases, the higher the better, no compromises. But in other cases, you have to go back to your business team or your SMEs And say, hey, what is acceptable for you?

[Faculty (Olympus)] 11:48:27
And if they say 75%, yeah, it's good enough for me, that 75% it is, right?

[Faculty (Olympus)] 11:48:33
And Anthony, you're right on the budget, the compute power, the stakeholder expectation. That is exactly what I'm speaking to right now.

[Faculty (Olympus)] 11:48:40
All right. So as a recap, we started here. We discussed and discussed and discussed with our business teams. We befriended the data. We cleansed the data, we trained the model.

[Faculty (Olympus)] 11:48:50
And then we decided how good is good enough, what success looks like.

[Faculty (Olympus)] 11:48:54
And then we make an agreement What should be the predictive performance? And when I say predictive performance, it could be recall, it could be precision, it could be accuracy.

[Faculty (Olympus)] 11:49:04
Try to speak in general terms because some business teams might be focusing on false negatives. Others might be focusing on false positives. So if you're speaking generally, then predictive performance is a good Good term to use. Okay, so now we have decided on the predictive performance and let's say

[Faculty (Olympus)] 11:49:21
We say that our success criteria, Renuka. Is… 95%, okay?

[Faculty (Olympus)] 11:49:30
Good enough 95%. Renochi agrees I go and I deploy this model now.

[Faculty (Olympus)] 11:49:36
Because Renuka is my boss, she says. 95%. And I got her 95%.

[Faculty (Olympus)] 11:49:43
What happens then? This is where rubber meets the road.

[Faculty (Olympus)] 11:49:48
This is where rubber meets the road. We plug in future data.

[Faculty (Olympus)] 11:49:54
And what is future data? It's the data that's now coming in. What's happening in the market now? Yes, I've trained the model on historical data.

[Faculty (Olympus)] 11:50:02
I've improved it. I've fine-tuned it. I trained it and then I also tested it on test data Before you deploy a model, not only that you train on training data, you will also test it on test data.

[Faculty (Olympus)] 11:50:17
To make sure that it is ready to meet the real world right here.

[Faculty (Olympus)] 11:50:22
And you've done that. And we have arrived 95%. And now I am deploying the model on you guys' behalf. And let's make Renuca our boss today.

[Faculty (Olympus)] 11:50:32
So now future data is how say what is the house price? What is the price of the oil? What is the price of crop these days?

[Faculty (Olympus)] 11:50:42
What is the student profile if I'm trying to figure out how many students are going to stay in this cohort and how many are going to churn?

[Faculty (Olympus)] 11:50:49
Who's going to pay the loan or not. Banks do that.

[Faculty (Olympus)] 11:50:53
They give loans in terms of millions of dollars, hundreds and thousands of dollars, right? So they want to make sure that based on Based on this profile.

[Faculty (Olympus)] 11:51:06
Historical data they're able to tell up here that who's going to make a payment and who's going to default right Our job as a data scientist doesn't stop here.

[Faculty (Olympus)] 11:51:21
Why? Because remember I told you that this is studying a real life process out in the business room. There's real people out there, customers, you and I, Right?

[Faculty (Olympus)] 11:51:33
Customers, you and I, there is a real life underlying process that could be supply chain, procurement, healthcare, banking, you name it, right?

[Faculty (Olympus)] 11:51:45
These are dynamic processes and these are dynamic people that always change.

[Faculty (Olympus)] 11:51:50
So when we put our model to production. When I put the model to production on all of you guys's behalf.

[Faculty (Olympus)] 11:51:58
I will monitor the model. For model drift.

[Faculty (Olympus)] 11:52:02
And what does that mean is that how much is my model drifting from what it did here?

[Faculty (Olympus)] 11:52:10
Okay. I'm going to do a quick pop quiz. Why are models drifting? I just spoke to it about a minute ago. Why would models drift?

[Faculty (Olympus)] 11:52:23
I'm looking at the chart right data is dynamic yes data we may start, Ravi Kumar, yes.

[Faculty (Olympus)] 11:52:31
Maybe there were not many outliers, but now we're starting to have outliers.

[Faculty (Olympus)] 11:52:36
Right? Future data may be unpredicted.

[Faculty (Olympus)] 11:52:40
Hats off on them. Yes. Dinesh Kumar, yes. Business has changed.

[Faculty (Olympus)] 11:52:45
Processes and people are dynamic new market forces anthony, yes. And they will influence what you did over here.

[Faculty (Olympus)] 11:52:56
So I will continue to monitor the model for drift. For fluid data, and I will continue to monitor the fluidity of this data And I'll come back to you guys again.

[Faculty (Olympus)] 11:53:09
And Renega is still the boss. So I'll come back to you guys again and I say, hey guys.

[Faculty (Olympus)] 11:53:13
How much drift is acceptable to you? It's going to happen.

[Faculty (Olympus)] 11:53:19
Drift is part of model deployment. It will happen. But how much again?

[Faculty (Olympus)] 11:53:25
We asked ourselves how much Good is good. And we ask ourselves here how much drift is acceptable, right? Is 3% okay?

[Faculty (Olympus)] 11:53:37
I don't decide that. You decide that. Because you're my you're my subject matter expert, right?

[Faculty (Olympus)] 11:53:43
If you say, well, I'm okay with 10%. I don't care. 10% it is.

[Faculty (Olympus)] 11:53:49
Normally, it's much less than that. Just not. So models must not drift too much outside of what you and your business teams have aligned on.

[Faculty (Olympus)] 11:54:01
So it's not like I've done so much work, I'm already six months into the project. It can take longer.

[Faculty (Olympus)] 11:54:07
I've put the model to production. Okay, thank you very much. I'll see you whenever I see you. No, you will continue to monitor the model for drift.

[Faculty (Olympus)] 11:54:16
And you will continue to fine tune the model. And all of this fine tuning the model, we fine tune the model called using a term called hyperparameters. Every algorithm has its own assortment of hyperparameters.

[Faculty (Olympus)] 11:54:33
That we use or choose And you will study all of that.

[Faculty (Olympus)] 11:54:38
Anthony says, can you plan for drift with metrics or just observe real world failures?

[Faculty (Olympus)] 11:54:44
Okay. What do you think? You've already given the answer here.

[Faculty (Olympus)] 11:54:49
Which would be less costly. I'm clean.

[Faculty (Olympus)] 11:54:54
Having a real world failure deciding on a metric here.

[Faculty (Olympus)] 11:55:03
Anyone. We decide on metrics so we say five percent real yes yes mate real world failures are going to cost a lot of money.

[Faculty (Olympus)] 11:55:16
End time and damaged goodwill It may even cost you your job.

[Faculty (Olympus)] 11:55:23
As a data scientist. So please don't rely on real world failures. Always come up with a metric, right?

[Faculty (Olympus)] 11:55:29
Ashish says, is the cost for running and maintaining a model ever becomes an issue when you're, okay, excellent question. Yes, it does become an issue. So these models These models here have a shelf life and it is exactly because of what you're saying

[Faculty (Olympus)] 11:55:44
That once the team thinks okay, my job is done.

[Faculty (Olympus)] 11:55:48
They may retard the model. These models are not. Actually, in my career, most of the models have had a shelf life.

[Faculty (Olympus)] 11:55:57
Because yes, ongoing maintenance management, fine tuning requires money.

[Faculty (Olympus)] 11:56:06
And sometimes teams don't have enough money. Yeah. Okay. Moving on.

[Faculty (Olympus)] 11:56:16
So we have a model now. We've done predictive performance fine tuning and we've learned that once we do our jobs are not done, we will continue to monitor for process drift and we'll continue to keep fine tuning our models, all of which cost money and time. And if the business has it.

[Faculty (Olympus)] 11:56:37
They'll do it. And if they don't have it, sometimes the business need is still there I've had cases like where the business need was still there, but the team ran out of funding.

[Faculty (Olympus)] 11:56:49
Almost 70% of these projects don't take off because of funding.

[Faculty (Olympus)] 11:56:55
Businesses get too excited about, okay, let's do it But when you start figuring out all the variables that go into doing it.

[Faculty (Olympus)] 11:57:04
And making it happen on a continual basis. Then they withdraw. So that is a very, very good input. Thank you for that. It's a very real part of data science world. Okay, so the types of machine learning, this is just a deep dive. I've already spoken about them.

[Faculty (Olympus)] 11:57:18
So when we're doing regression, which is prediction problem, or we're doing classification.

[Faculty (Olympus)] 11:57:25
Which is, does this person have COVID or not? Will this person do fraud or not, right?

[Faculty (Olympus)] 11:57:31
These are called supervised learning problems. I'm going to pull this up here again. Look at this Excel sheet.

[Faculty (Olympus)] 11:57:39
And tell me it's called supervised learning. We all agree, but why? Who's supervising?

[Faculty (Olympus)] 11:57:47
Who's the supervisor here?

[Faculty (Olympus)] 11:57:55
Data. Inputs, collected data, features. Features are your columns, by the way. Yes.

[Faculty (Olympus)] 11:58:05
Absolutely. You guys are right on. So this data this data and the labels, if I was classifying, is somebody going to be married or not?

[Faculty (Olympus)] 11:58:17
I have labels here. And if I was predicting what's the salary of a I also have salary information from the past, right?

[Faculty (Olympus)] 11:58:28
So these are the supervisors. So it's learning from supervised or labeled data, right?

[Faculty (Olympus)] 11:58:35
So classification problems One classic example that we encounter every day is spam email detection.

[Faculty (Olympus)] 11:58:43
So how does it work? How does that algorithm work? It's studied a lot of females and it's tried to identify patterns What a good email looks like.

[Faculty (Olympus)] 11:58:55
What a good email address looks like. What kind of subject line is contained in a good email? What kind of text body is in a good email, right? And then it's also studied bad email.

[Faculty (Olympus)] 11:59:10
Based on its learnings. It's now able to tell us whether an email goes to spam or not. Does it ever make a mistake?

[Faculty (Olympus)] 11:59:19
Yes. Have you ever had this conversation where, oh, I sent you an email and I said, no, I didn't get an email. And then you would tell me, well, could you please check your spam folder?

[Faculty (Olympus)] 11:59:29
Why do you think that happens? That happens when the model misclassifies.

[Faculty (Olympus)] 11:59:34
And you will study about misclassification in your upcoming sessions. Or modules, right? So yes, the models can misclassify, but our job as a data scientists When we are trying to improve on the predictive performance of the model, we'll make sure that misclassifications happen

[Faculty (Olympus)] 11:59:52
As low as possible. So it's not a common day occurrence that 15 of your emails are getting incorrectly misclassified. Your email from your boss is going to spam folder? No.

[Faculty (Olympus)] 12:00:02
It happens once in a blue moon. Somebody says, well, you signed a contract. I didn't get it. We'll go check your spam folder.

[Faculty (Olympus)] 12:00:09
Maybe… something was detected by the algorithm in that email that it thought was suspicious.

[Faculty (Olympus)] 12:00:16
Okay. Bank loan approval again classification problems, regression problems when we are trying to predict a continuous numerical variable. We're trying to predict on a number.

[Faculty (Olympus)] 12:00:29
What is the age number? What is the price of crop?

[Faculty (Olympus)] 12:00:34
Number, right? How much would I pay for my child's education if I send him to Harvard?

[Faculty (Olympus)] 12:00:42
Number, okay? So this is called supervised learning.

[Faculty (Olympus)] 12:00:50
Now, let's move on to move on unsupervised learning.

[Faculty (Olympus)] 12:00:56
So unsupervised learning happens When you don't have label data.

[Faculty (Olympus)] 12:01:03
When might that happen? So let's say Amazon. That's an example everyone can relate to. So millions of people across the world by a vast variety of products from Amazon.

[Faculty (Olympus)] 12:01:19
It's not labeled data, but what if Amazon says well you know I want to cluster people who are in the city of New York and I want to see what kind of purchases they're doing

[Faculty (Olympus)] 12:01:34
If they are aged between 30 and 35. That could be one cluster, right? So unsupervised learning is the exact opposite of supervised learning.

[Faculty (Olympus)] 12:01:43
It is when the data is not labeled and you're trying to sift through a lot of information and you're trying to form clusters based on similarity.

[Faculty (Olympus)] 12:01:53
So for example. You know, unbeknownst to you and I, airlines And any merchant for that matter is always doing some kind of cluster analysis on us.

[Faculty (Olympus)] 12:02:05
Every transaction that you make at a brick and mortar store or any transaction that you make online is being used to do some kind of cluster analysis. What cluster does this customer fall into.

[Faculty (Olympus)] 12:02:21
Clusters could be women unmarried going to college. One cluster could be.

[Faculty (Olympus)] 12:02:27
It could be people who are married and have no kids.

[Faculty (Olympus)] 12:02:31
Another cluster. It could be people who are constantly taking vacations to like beach destinations like Costa Rica or Hawaii. So that's one cluster good cluster for airlines to do marketing, right?

[Faculty (Olympus)] 12:02:44
So unsupervised learning can help us in clustering. It can also help us in dimensionality reduction.

[Faculty (Olympus)] 12:02:52
So going back to what we were discussing about 40 minutes ago.

[Faculty (Olympus)] 12:02:56
All 500 columns if you get or all 80 columns are not necessary.

[Faculty (Olympus)] 12:03:04
To do the job. So who decides Should I just say, oh, you know what like yeah these last 15 columns, just chop them off.

[Faculty (Olympus)] 12:03:14
I could come to you for a better input. And I could say, hey, you're the subject matter expert Tell me which of these columns matter. And you will say, okay, well, these 25 matter.

[Faculty (Olympus)] 12:03:25
But then is that good enough? How about we let the machine decide using statistics that why don't you study the data and provide me with a meaningful compression?

[Faculty (Olympus)] 12:03:37
You tell me mathematically which of the variables or features are having an impact.

[Faculty (Olympus)] 12:03:44
So unsupervised learning has applications clustering and dimensionality reduction I'm going to pause here.

[Faculty (Olympus)] 12:03:54
And check for and check Q&A.

[Faculty (Olympus)] 12:04:02
So somebody asked, does machine learning work with unstructured data? Can you please share examples exactly So unsupervised learning can take unstructured data. And I just spoke to it.

[Faculty (Olympus)] 12:04:18
Okay, will we get access to this slide? Yes, you will have recording of the session and access to the slides, yes.

[Faculty (Olympus)] 12:04:28
Okay, so there's a lot of questions on Jenny. Guys, let's keep moving, please. And I'll stay on after the session to answer the questions on Gen AI.

[Faculty (Olympus)] 12:04:38
So unsupervised learning, I put this example together for you guys to drive home the point So data, unlike supervised learning.

[Faculty (Olympus)] 12:04:47
Right? Clean data. You look at marital status and you can understand right away, okay, married, unmarried, perfect. I understand what that means. We all do.

[Faculty (Olympus)] 12:04:55
What about if you get data like this?

[Faculty (Olympus)] 12:05:01
What do you make of it? Don't look here. That's a different thing I'm going to talk about. Just look up here, row one to four.

[Faculty (Olympus)] 12:05:08
You've got data like this. It's data on product. Product specifications.

[Faculty (Olympus)] 12:05:16
That is a classical If I have to cluster based on similarity cluster products.

[Faculty (Olympus)] 12:05:24
Into groupings. This could be unsupervised learning now If the same data I label it and I say, well, this is wall These are flanges, these are pipes These are pumps and I label all, let's say 15,000 rows in my data

[Faculty (Olympus)] 12:05:43
Now this becomes labeled data, right? Now if I have to classify what is what.

[Faculty (Olympus)] 12:05:51
Now this is a classification problem. Okay.

[Faculty (Olympus)] 12:05:57
Does that make sense, guys?

[Faculty (Olympus)] 12:06:02
It's complex, Tranika, yes It's unstructured, yes.

[Faculty (Olympus)] 12:06:06
That is why you want to do clustering. Clustering so just clustering so So it's labeled data structure data. Yes. So each labeled data is structured data if you just glance at this sheet. Kent, I'm going to get back to your point

[Faculty (Olympus)] 12:06:21
If you just glance at it, it's structured data, right? It's structured and it's labeled. So Kent is asking a very good question, actually. Do the features emerge from the data or are they imposed? No.

[Faculty (Olympus)] 12:06:34
When you're clustering, you're studying all the features. And based on the features, you're saying put this similar group here, put this similar group here could be cluster ABC, could be cluster one, two, three.

[Faculty (Olympus)] 12:06:47
Could be cluster. Could be clustered married, non-married, unmarried, married with kids, divorced. I mean, if you do that, that's already labeled, right?

[Faculty (Olympus)] 12:07:01
So can we have a cluster inside a cluster, which Vanath is asking?

[Faculty (Olympus)] 12:07:08
You guys are ahead of me. Great cohort today. Let me get to that here. Can we have a cluster inside a cluster?

[Faculty (Olympus)] 12:07:15
So I'm going to ask you guys this. Supervised learning we have the label data.

[Faculty (Olympus)] 12:07:22
So we knew what good answers looked like right Unsupervised learning, we didn't have labeled data. We had unstructured data. So then who decides Is a cluster good enough?

[Faculty (Olympus)] 12:07:36
Who decides that? This is exactly talking about can we have a cluster inside our cluster?

[Faculty (Olympus)] 12:07:45
Who is deciding over here Let's say, again, I'm your data scientist. You guys are my bosses, all of you.

[Faculty (Olympus)] 12:07:52
And I make clusters students who are studying AIML, students who are doing a PhD in AIML, and students who are aspiring to study AI enough. So who decides what cluster should people be or students be in business stakeholders So when you and i

[Faculty (Olympus)] 12:08:13
Are here, we don't know what right looks like. So we do cluster analysis and we go back to the business And then the business can say.

[Faculty (Olympus)] 12:08:23
Hey, Kent. Thank you for doing this initial analysis, but I feel like in cluster B, It could be further refined.

[Faculty (Olympus)] 12:08:33
Cluster B could be split in two or three or however many clusters. So let's go back and let's redo the exercise and refine the cluster.

[Faculty (Olympus)] 12:08:44
Right? Does that make sense, Kent?

[Faculty (Olympus)] 12:08:51
So in cluster, okay, perfect. In unsupervised learning, you do cluster analysis, you go back to the person who's paying for the project, who's the business owner.

[Faculty (Olympus)] 12:09:01
Sorry business process owner and you say, hey, do these clusters make sense?

[Faculty (Olympus)] 12:09:06
So this is a project I've kind of like fudged this data because I can't share the exact project specifications for you for confidentiality reasons but When I made these initial clusters.

[Faculty (Olympus)] 12:09:17
This was massive data. It took me a very long time more than three months.

[Faculty (Olympus)] 12:09:26
To just make sense of the data and come up with initial cluster analysis. And then I did exactly what all of you guys are putting in chat. I went back to the business and I said, this is what I've come up with. Does it make sense?

[Faculty (Olympus)] 12:09:36
And I'll share a funny finding with you. The importance of talking to the business.

[Faculty (Olympus)] 12:09:46
I'm trying to think of writing that. So let's say there was something

[Faculty (Olympus)] 12:09:55
I'm trying to do a clear reflection and I'm fudging data on the go let's say the value was pumped 360-net.

[Faculty (Olympus)] 12:10:07
Okay. So what happened in my initial cluster analysis

[Faculty (Olympus)] 12:10:16
The algorithm classified everything with the word bump In it, followed by a number is one cluster.

[Faculty (Olympus)] 12:10:23
So I thought that this was a thought Pumps are a product, right?

[Faculty (Olympus)] 12:10:29
Pumps are a product. But when I went back to business.

[Faculty (Olympus)] 12:10:33
They say that this was an abbreviation of the vendor who they were buying things from. This was the name of the vendor.

[Faculty (Olympus)] 12:10:42
It was not even a product. So that is the value of always verifying your cluster analysis and refining it.

[Faculty (Olympus)] 12:10:50
After touching base with the business, right? If you see pumps here pumps don't even have the word pump.

[Faculty (Olympus)] 12:10:58
Isn't that right? So my initial cluster analysis was actually further reinforced with human input.

[Faculty (Olympus)] 12:11:07
Business refinement is like they say, well, this PUMP is actually abbreviation of the vendor that we buy.

[Faculty (Olympus)] 12:11:15
Buy these products from them. So this was not a meaningful cluster.

[Faculty (Olympus)] 12:11:20
Good points, guys. Okay, so moving on. So we've learned machine learning, supervised learning.

[Faculty (Olympus)] 12:11:27
Unsupervised learning are sub branches of machine learning. And then I've already spoken to this slide in great detail. We have reinforcement learning here. So reinforcement learning is based on So this program, by the way, covers supervised learning and unsupervised learning in great detail.

[Faculty (Olympus)] 12:11:45
But it doesn't cover reinforcement learning. As an intro, reinforcement learning is exactly what the name says. It's based on rewards and penalties.

[Faculty (Olympus)] 12:11:54
So if you do a good job, I will come in as a human.

[Faculty (Olympus)] 12:11:59
And I will reward you. So you will know that, okay, if this is the good answer. This was the good one.

[Faculty (Olympus)] 12:12:06
And if you make a mistake, I will penalize you. So the system would know, okay, this was probably not a good move.

[Faculty (Olympus)] 12:12:15
If you have ever been to SeaWorld, have you ever, has anybody been to SeaWorld you know in those dolphins, they perform.

[Faculty (Olympus)] 12:12:25
They always line up and their trainers are throwing fish in their mouth because they they're trained on that reward system they know If I do this move, if I perform this feat.

[Faculty (Olympus)] 12:12:37
I'm going to get rewarded for it, right? So that is just a general description of reinforcement learning.

[Faculty (Olympus)] 12:12:45
All right, so what is deep learning? Somebody was asking, can you please explain what neural networks are? So deep learning generative AI is based on neural network in a very, very plain feel a plain example of neural network is in front of you. Could this be simpler?

[Faculty (Olympus)] 12:13:02
Yes and could this be more complex, which almost always it's going to be more complex architecture than this The answer is yes.

[Faculty (Olympus)] 12:13:11
So how does a neural network work let's work let's work let's It still takes data. So these orange dots These are your data points. So you will still feed in data. Data will get converted into numbers.

[Faculty (Olympus)] 12:13:25
This is your output. This is the answer that you're trying to get to.

[Faculty (Olympus)] 12:13:32
This is known your data is known, right? You will feed data and you will know the data which will then get converted into numbers by a neural network.

[Faculty (Olympus)] 12:13:41
And you will also know what you're trying to get at. You will know, am I trying to predict price of a car or am I trying to figure out will somebody churn or not? An employee churn or not after 10 years of employment?

[Faculty (Olympus)] 12:13:54
So inputs and outputs are known. What happens in the middle, these are called hidden layers.

[Faculty (Olympus)] 12:14:01
This is the architecture of neural network. It's by far my most favorite subject to teach is neural networks because it's amazing how they work.

[Faculty (Olympus)] 12:14:09
And the math behind them is so intense and powerful. So you guys will love those sessions, by the way.

[Faculty (Olympus)] 12:14:16
So these are the hidden layers. It's the architecture. Of a neural network, the architecture will get defined by you.

[Faculty (Olympus)] 12:14:24
How many hidden layers do you have? So this is one hidden layer. This is the second hidden layer. How many hidden layers to have?

[Faculty (Olympus)] 12:14:33
And how many neurons to have in each hidden layer? For illustration purposes, they have put the equal number of neurons in each layer. It doesn't have to be that.

[Faculty (Olympus)] 12:14:42
This could have 12, this could have 512, who knows? How will you decide which architecture is good architecture?

[Faculty (Olympus)] 12:14:53
Because the options are endless, right? You could have 30 layer neural network, which would require immense compute power.

[Faculty (Olympus)] 12:15:02
Large volumes of data. Or you could have a smaller neural network, just four layers, right?

[Faculty (Olympus)] 12:15:09
So what decides that is when you train a neural network, you will have a whole army of hyperparameters that you can fine tune and you can see what gets me closer to this outcome.

[Faculty (Olympus)] 12:15:21
And that helps you decide what the architecture of your neural network should be.

[Faculty (Olympus)] 12:15:28
Okay.

[Faculty (Olympus)] 12:15:33
Any questions?

[Faculty (Olympus)] 12:15:38
Is this clear neural networks? I'm giving you again a very high level overview. It's much more deeper and complex than that.

[Faculty (Olympus)] 12:15:47
But this is how a neural network works. Clear as mud Jesus, okay, let's play a game.

[Faculty (Olympus)] 12:15:56
I don't want it to be clear as much. I want it to be crystal clear. Let's play a game.

[Faculty (Olympus)] 12:16:02
Um… And the game is… Yes, Kishore. It's refining data towards the target but As it does that, as it defines the data towards the target, which is your green dot, your green neuron.

[Faculty (Olympus)] 12:16:16
Right? It goes back and forth, back and forth. So as the data travels here, there is forward propagation. Then it says, ah, you know, this wasn't right. It comes back and that's called backward propagation, right?

[Faculty (Olympus)] 12:16:30
So Arun, when Arun asks what is the neuron purpose here in this deep learning, that is what the neuron purpose is.

[Faculty (Olympus)] 12:16:37
Is to process this data extract the learnings from this data numerically Assign some nonlinearity to it.

[Faculty (Olympus)] 12:16:49
And then keep going forward, keep passing All of these hidden layers, however many hidden layers are there, and come to this green dot, green neuron.

[Faculty (Olympus)] 12:16:59
And then you say, okay, I've made a mistake. And then you come back.

[Faculty (Olympus)] 12:17:04
And you look back And you say, well, I was not alone. This guy was, this neuron was not alone making a mistake. This neuron was not alone in making a mistake.

[Faculty (Olympus)] 12:17:14
This mistake was collectively made by all of these neurons. So as part of backward propagation, which is the purpose of neurons.

[Faculty (Olympus)] 12:17:23
I will distribute the error equally and I'll go back here and then I'll feed forward again and I'll keep doing it.

[Faculty (Olympus)] 12:17:30
Until I get to the right answer. So lots of permutation and computations happen.

[Faculty (Olympus)] 12:17:37
And the purpose of neurons is neurons how good or strong do you want those weights and biases Weights are the numerical values that get assigned here.

[Faculty (Olympus)] 12:17:51
How many times are these values going to be adjusted numerically? This is all happening numerically.

[Faculty (Olympus)] 12:17:58
Because once you have fed your data into into your neural network is all a number scale.

[Faculty (Olympus)] 12:18:05
So when the data goes towards the target. Forward propagation.

[Faculty (Olympus)] 12:18:10
It reaches the target that says, ah. I made a mistake. I need to fix it.

[Faculty (Olympus)] 12:18:16
Let's go back. As it travels back over here backward propagation.

[Faculty (Olympus)] 12:18:22
So Ashish, when you say an example of a neural network will help, that's exactly what I'm explaining. This is how a neural network works, right?

[Faculty (Olympus)] 12:18:29
And arrows, these arrows so every these are fully connected densely connected neural networks. So each neuron is talking to the other neuron.

[Faculty (Olympus)] 12:18:40
It's like an intertwined back and forth propagation, right? So if you need an example, let's say I want to a real life example of a neural network.

[Faculty (Olympus)] 12:18:56
Okay, yes, let's do that. And it's the amount of back and forth propagation depends upon the result expected. Exactly.

[Faculty (Olympus)] 12:19:04
Sadly. This is what's driving the feed forward, the forward propagation.

[Faculty (Olympus)] 12:19:12
And the backward propagation, right? This thing, the outcome that you're trying to accomplish So let's say I'm trying to predict let's so neural networks can do prediction problems and neural networks can also do classification problems And there is a saying out in the industry that as long as

[Faculty (Olympus)] 12:19:34
As a solution exists. Neural network will find it for you.

[Faculty (Olympus)] 12:19:40
So does it mean we should always just use neural network for every single problem that we run across? Because we know it's statistically powerful. It has an architecture.

[Faculty (Olympus)] 12:19:49
That you and I have power on? No. Why? Because it is computationally intensive and you guys will see when you guys start to train a neural network in your course, it takes time.

[Faculty (Olympus)] 12:20:04
And you need lots of data. Lots of data.

[Faculty (Olympus)] 12:20:09
Probably three, four times data than what you would need for machine learning problems.

[Faculty (Olympus)] 12:20:15
To train a neural network. So if those are if compute power and the volume of data is your limitation, then probably you will not use a neural network to do a classification.

[Faculty (Olympus)] 12:20:25
Or a regression problem, right? So let's say if you have to come up with a real world example, let's say I'm trying to predict the age. I'm using neural network for a prediction problem, right? And I say that age is 30.

[Faculty (Olympus)] 12:20:39
So in this neuron, I know the right answer. It's 30.

[Faculty (Olympus)] 12:20:45
I feed all the data and let's say the data looks something the data is this Matt sent this is the data. This is what I'm feeding.

[Faculty (Olympus)] 12:20:54
Right. And I'm saying, well, my right answer is this. This information this x1, X2, X3, X4, x5.

[Faculty (Olympus)] 12:21:04
This is your age, education, experience, salary, marital status, kids. Residents and it could be a hundred other columns right Okay. So we… We're here now. This data enters your neural network As it enters the neural network.

[Faculty (Olympus)] 12:21:23
It will in the first hidden layer weights numerical weights Numerical weights will be randomly initialized. This layer in easy terms, it will say, okay, I'm seeing all of these variables coming at me.

[Faculty (Olympus)] 12:21:35
Let me randomly assign some values to them. Some weights to them.

[Faculty (Olympus)] 12:21:41
And then I'll pass on, I'll add a bias to do an activation function. And guys, these are advanced terms Please wait till you reach the session because I don't want to confuse the mass audience here.

[Faculty (Olympus)] 12:21:54
But what happens is weights get randomly initialized here. Along with vices plus activation function.

[Faculty (Olympus)] 12:22:02
Activation function adds nonlinearity because remember, you're trying to deploy a neural or employ a neural network to study a complex nonlinear problem.

[Faculty (Olympus)] 12:22:12
So that's why you need activation function. So all of this is happening in this layer. And as this passes forward and forward and forward, maybe you have 10 hidden layers, each with 100 neurons in it.

[Faculty (Olympus)] 12:22:26
It adjusted it adjusts itself until it gets here. And it sees oh okay The answer was 30. Ouch. I came at 25. So I'm off by five. I made a mistake.

[Faculty (Olympus)] 12:22:41
It goes back. It says, I didn't make this mistake alone let me distribute the errors here. It will back propagate all of those computations occur and then it feed forwards again until it gets as close as possible to the right answer.

[Faculty (Olympus)] 12:22:57
Right. That is how a neural network. Does that help?

[Faculty (Olympus)] 12:23:03
Okay. Veronica says, while I wait for Kent's answer, Renika says, I'm thinking ChatGPT works. Yes, deep learning.

[Faculty (Olympus)] 12:23:11
Deep learning is standing. It has an architecture of like transformer architecture, encoder decoder architecture But after that is done, on top of that sets a neural network, absolutely.

[Faculty (Olympus)] 12:23:28
Absolutely. So when we are giving a prompt.

[Faculty (Olympus)] 12:23:33
And it gives us an answer and you say, well, thank you.

[Faculty (Olympus)] 12:23:36
But can you make it better? I was looking for X, Y, and Z.

[Faculty (Olympus)] 12:23:41
It goes back and it searches through and it tries to get as close as possible to your prompt That is exactly what's happening behind the scenes. Of course, there's much more. We have a whole like a transformer architecture that is

[Faculty (Olympus)] 12:23:56
At uh at the at the backbone of chat GPT.

[Faculty (Olympus)] 12:24:03
So you guys will learn more. It's more specifically a decoder architecture used by GPT.

[Faculty (Olympus)] 12:24:09
But you guys will learn more of that in your, I believe it's the last module of your program, right?

[Faculty (Olympus)] 12:24:16
Okay, so in interest of time, I have to keep moving on.

[Faculty (Olympus)] 12:24:18
Again, if anybody is feeling that they're unheard or their questions are not being answered, I will stay past the session to make sure that I address all of the queries, right?

[Faculty (Olympus)] 12:24:30
So… Before I do that, there's more input.

[Faculty (Olympus)] 12:24:37
So each Arun is saying, each of neuron outcome is defined to process a specific scenario.

[Faculty (Olympus)] 12:24:46
It's designed to model as accurate of a response to the outcome as possible, right?

[Faculty (Olympus)] 12:24:55
So yeah, you're fairly close yeah

[Faculty (Olympus)] 12:25:03
Okay, so let me… Thank you, moving on.

[Faculty (Olympus)] 12:25:07
Guys, this is me. I could talk about neural networks for hours and I'm trying making an honest effort to not get caught in explaining neural networks because you would love the architecture and the amazing ways in which you can harness the power of a neural network.

[Faculty (Olympus)] 12:25:23
Yeah, these are probably one of the best modules that you will have.

[Faculty (Olympus)] 12:25:26
Coming up for you. Okay, so now that we've studied machine learning, supervised learning, unsupervised learning, use cases of each.

[Faculty (Olympus)] 12:25:35
Broadly. Ai. So we've studied the kinds of machine learning. So the kinds of AI at very high 30,000 feet level can be divided into discriminative AI or generative AI.

[Faculty (Olympus)] 12:25:48
Discriminative AI is yes or no. Will it rain or not?

[Faculty (Olympus)] 12:25:53
Right? That is discriminative AI. Yes or no?

[Faculty (Olympus)] 12:25:59
Is this an image of a cat or a dog? Discriminating between this and this.

[Faculty (Olympus)] 12:26:05
Is it this or this, right? And we talked about it in classification.

[Faculty (Olympus)] 12:26:11
Generating AI, it's generating new content. So you can say generate an image of a dog having fun in a party, wearing a black tuxedo with wine in one hand.

[Faculty (Olympus)] 12:26:22
Now, if you think about this text just in English language terms.

[Faculty (Olympus)] 12:26:26
Without even thinking about Gen AI, right? Don't forget Geniak. You're just saying, well, you're reading a sentence.

[Faculty (Olympus)] 12:26:35
Image of a dog having fun in a party. That's a dot.

[Faculty (Olympus)] 12:26:39
Docs are normally not seen having fun at a party. On top of that, wearing a black tuxedo that's like out of the window, right? With wine in one hand So we know that this scenario cannot exist in a real life.

[Faculty (Olympus)] 12:26:56
But if you take this sentence out of a paper and you use it as a prompt.

[Faculty (Olympus)] 12:27:02
What the model, a large language model would do for you is it's a studied All of these in separate components.

[Faculty (Olympus)] 12:27:12
It's studied what the word dog means. It's understood what the word image means.

[Faculty (Olympus)] 12:27:18
It understood what the word having fun means. A party wearing a black tuxedo vine in one hand Your prompt will be processed through a large language model.

[Faculty (Olympus)] 12:27:33
Which, in addition to the transformer architecture, also has a neural network.

[Faculty (Olympus)] 12:27:40
Embedded in it, right? So based on all of these understanding.

[Faculty (Olympus)] 12:27:45
The large language models. So let me briefly talk about large language models. Large language models have Learn from copious amounts of data. They scrape the web.

[Faculty (Olympus)] 12:27:55
Chatgpt 3.5 was trained. 300 billion word tokens And 175 billion.

[Faculty (Olympus)] 12:28:04
With the B parameters. And when I say parameters, it's these guys, the weights and biases and the activation functions. It's your weights and biases.

[Faculty (Olympus)] 12:28:13
It's learn the context. In which context every word is said, what comes before if I say The sun rises from the east.

[Faculty (Olympus)] 12:28:24
It understands there always comes before the sun, right? And if it says the sun rises, it cannot be best after that. It has to be east.

[Faculty (Olympus)] 12:28:34
It's understood the positions of the word The context of the word and the meaning of the word.

[Faculty (Olympus)] 12:28:40
So I use this example quite frequently with my students in class.

[Faculty (Olympus)] 12:28:45
But I'm going to use that example here with you. To drive home the point that how is this even working So if I say Renuka, I sat by the riverbank Ranukkah knows what she's talking about. It's a water bottle, right? And I go to Kent and i say kent

[Faculty (Olympus)] 12:29:03
Yesterday, I could not deposit my money in the bank. So without me having to tell Kent, Kent knows well she's not talking about like a river body or some other bank. It's a financial institution.

[Faculty (Olympus)] 12:29:16
Right. And if I come to everybody else in this class and I say, guys.

[Faculty (Olympus)] 12:29:21
I've got two kids by 10 p.m. My bank of energy is exhausted.

[Faculty (Olympus)] 12:29:27
You guys would know what I mean. If I tell you guys my bank of clothes is really outdated.

[Faculty (Olympus)] 12:29:35
You guys will know it's not a financial institution, but it's a store offer clothing, right?

[Faculty (Olympus)] 12:29:41
Same word, bank. Used in different contexts.

[Faculty (Olympus)] 12:29:46
So what these LLMs have done is that they've learned all the different contexts that the word bank could appear in what comes before, what comes after does it make sentence of a structure?

[Faculty (Olympus)] 12:30:01
It's learned all the ways you and i writing.

[Faculty (Olympus)] 12:30:07
And it's understood a sentence like my bank by 10 p.m. Energy, that's not how these species speak.

[Faculty (Olympus)] 12:30:16
They cannot say something like this goes, it doesn't make sense.

[Faculty (Olympus)] 12:30:20
So these LLMs have learned that. That's what's here.

[Faculty (Olympus)] 12:30:26
That's your chat GPT. 3 and 3.5 and 4 and 4. Oh, you name it. That's all of them here. That's what they've done.

[Faculty (Olympus)] 12:30:36
So now that they've understood all the context, all the different meanings, all the positional placements.

[Faculty (Olympus)] 12:30:42
They are able to stitch together this image for you because they know what image means dog having fun, a party tuxedo, black tuxedo wine in one hand.

[Faculty (Olympus)] 12:30:58
So they are stitched together a mosaic of all of these Because not that they studied this image.

[Faculty (Olympus)] 12:31:06
Not that they studied this. The SMH did not exist until You asked for it.

[Faculty (Olympus)] 12:31:14
But how did it create that image? It's because it's learned all of the language that we have.

[Faculty (Olympus)] 12:31:23
Does that make sense? It's important to know what's important to know what's behind the scenes.

[Faculty (Olympus)] 12:31:33
In a large language model. So Suresha is asking, there are a lot of senseless content in the internet that would that not pollute the model? Excellent question. So a bit out of context for this session today.

[Faculty (Olympus)] 12:31:46
Yes. It would. Remember what I told you on slide number one?

[Faculty (Olympus)] 12:31:53
Anytime you hear the word AI, whether it's machine learning, deep learning, generative AI, You think data ai data It's as good as the data. So to answer your question.

[Faculty (Olympus)] 12:32:09
These models, the primitive versions, were racist versions of LLMs. They were more biased towards gender. They were more biased towards employment structures, religion, but as these have evolved and finessed over time.

[Faculty (Olympus)] 12:32:29
There are system embedded instructions which is it's like DNA, right? You and I have a DNA. So we define, we as trainers define the DNA and we hard code these instructions in the model. So there is one prompt that sits here in the front.

[Faculty (Olympus)] 12:32:45
There's one prompt, but there are system prompts hard coded into their memory where you can say do not respond to things that are of political nature, do not respond to queries that are inappropriate.

[Faculty (Olympus)] 12:33:00
That may instigate hate. Crime did not respond to sexual content or so on and so forth right so great question. It can pollute the model. If you do not make an effort to harness the model. You tell the model.

[Faculty (Olympus)] 12:33:18
These are the constraints. So I'll give you, actually, Joshua, you make a good point. Let me share this with you. So I was teaching AI to AI fifth graders.

[Faculty (Olympus)] 12:33:31
And the kids are being kids One of the things, it's not a formal teaching I was doing. It was a fun session that I was volunteering to do at my daughter's school.

[Faculty (Olympus)] 12:33:42
And the kids uh i had uh i had uh Adobe Stock pulled up and I was entering in prompts.

[Faculty (Olympus)] 12:33:50
So it was a fun activity. Kids were giving me fun prompts, well, show me a teacher flying in the air in a classroom or show me a teacher eating tons of candy and it was generating those prompts. So it was a fun sashing.

[Faculty (Olympus)] 12:34:03
And at one point a child said that, show me an image of SpongeBob.

[Faculty (Olympus)] 12:34:09
Beating Superman. Do you guys all know SpongeBob or like Superman like characters like if you have kids, I don't think you can exist without not knowing SpongeBob and Superman. Yeah. Yeah, right? Yeah.

[Faculty (Olympus)] 12:34:24
So it responded that these are copyrighted characters.

[Faculty (Olympus)] 12:34:32
So SpongeBob is copyrighted and so is Superman. And also beating up was detected as like it's violence So it showed in a nice prompt back that, sorry, I cannot generate content that is based on violence or use copyrighted characters. Would you like to

[Faculty (Olympus)] 12:34:50
Do X, Y, and Z instead. So that's a classic example to answer your question that yes, it can pollute the models.

[Faculty (Olympus)] 12:34:57
But remember, these models have two kind of prompting.

[Faculty (Olympus)] 12:35:02
One is the front end prompt. I'll get back to that, Erica. If you're working with licensed costs and just bear with me for 30 seconds.

[Faculty (Olympus)] 12:35:11
So one is the front end prompt that you will do here.

[Faculty (Olympus)] 12:35:16
There are backend prompts that were hard-coded to define the brain.

[Faculty (Olympus)] 12:35:21
To define the DNA of this model. And that's exactly what those hard-coded prompts do.

[Faculty (Olympus)] 12:35:26
Right? So for example, when I'm working in my team, not my team.

[Faculty (Olympus)] 12:35:32
My company with different teams And I help them train their custom GPTs.

[Faculty (Olympus)] 12:35:37
Those custom GPTs are sitting on top of these LLMs. So they're sitting on top of GPT-3s and fours And when you train a custom GPT, you have an option. There is a section called instructions and you can write very, very fine

[Faculty (Olympus)] 12:35:56
Fine-grained instructions and you can say avoid reaching out to web.

[Faculty (Olympus)] 12:36:04
Erica, now I'm also addressing your Question here. What if you're working with licensed content? So as you're defining those instructions.

[Faculty (Olympus)] 12:36:13
Or hard coding your model, you can say, don't go out on grab I'm training you on my data. Only look at my data.

[Faculty (Olympus)] 12:36:20
And this is a classic use case if you're dealing with licensed content.

[Faculty (Olympus)] 12:36:24
Classic use case. Okay, good. Classic use case if you're dealing with sensitive information such as financial information.

[Faculty (Olympus)] 12:36:32
Classic use case when you're dealing with legal information, health information, right?

[Faculty (Olympus)] 12:36:37
You could also say you could also Search through the knowledge base that I'm uploading in you.

[Faculty (Olympus)] 12:36:44
If you don't find an answer. Go out on the web to search for it.

[Faculty (Olympus)] 12:36:51
I was working with a team where they had, I have to find ways to explain it where confidentially confidentiality doesn't get breached so Policy changes, right?

[Faculty (Olympus)] 12:37:02
Policy changes all the time. So in this particular case for this team, we say that, okay, look through our policies but If a policy on sustainability, let's say for example If a policy on sustainability has changed in Brazil.

[Faculty (Olympus)] 12:37:17
Also look on the outside web because I want to stay updated.

[Faculty (Olympus)] 12:37:22
So those are all the backend prompts that you can do to hard code. Remember, guys, these models, these LLMs, they don't have intuition.

[Faculty (Olympus)] 12:37:33
They are not thinking. They don't have thinking ability.

[Faculty (Olympus)] 12:37:37
All they are doing is they're doing is what they have learned from.

[Faculty (Olympus)] 12:37:42
What they've been trained on. Training is the right word here. What they've been trained on, right?

[Faculty (Olympus)] 12:37:47
They're not taught machines. They were trained on massive amounts of data and they've learned that I sat by the riverbank and i sat by the bank

[Faculty (Olympus)] 12:37:59
My bank of clothes is out. They did the same word, but has completely different meaning, right?

[Faculty (Olympus)] 12:38:06
So Suresh, you say they come very, very close conversationally yes But the way they come very, very close conversationally is how well they have understood your and my language.

[Faculty (Olympus)] 12:38:19
That's how exactly you're right. That's how well they have learned the language. The fact that, let's say, what if This prompt was not this. What if this prompt was what's the more or what is this month march okay so valentine's Day just passed, but I'm trying to come up with examples that are as close to the time we're in as possible. So let's say

[Faculty (Olympus)] 12:38:44
It was not a prominent generated image of a dog with a tuxedo. Let's say you're saying, hey, my wife has blue hair Sorry, blue eyes blonde hair She loves vanilla ice cream.

[Faculty (Olympus)] 12:38:58
And she loves to party. Help me write a Valentine's Day card for her.

[Faculty (Olympus)] 12:39:04
So to Suresh's point, yes, it will come very, very close conversationally and it will write a Valentine's Day card based on the description given to it.

[Faculty (Olympus)] 12:39:14
But that does not mean that does not mean that it's thinking.

[Faculty (Olympus)] 12:39:18
It means that it's learned the language that you and I speak so well that it's able to put those little bits of information together and generate a response for you.

[Faculty (Olympus)] 12:39:31
Does that make sense, guys? Suresh and everyone else?

[Faculty (Olympus)] 12:39:38
Does that… Yeah. Yeah. Okay, cool.

[Faculty (Olympus)] 12:39:42
All right, so moving on.

[Faculty (Olympus)] 12:39:47
If your wife or girlfriend may not know. If it was AI generated, yes, if you're doing that, then please don't tell them.

[Faculty (Olympus)] 12:39:56
That you're… generating AI written romantic notes. Okay, moving on.

[Faculty (Olympus)] 12:40:01
All right, so this ends this session in terms of grounding the content.

[Faculty (Olympus)] 12:40:07
And understanding the understanding the terminology and what it means and how they're interconnected. So let's spend about 60 seconds into the journey so far. So we started here and then we have a quiz to take.

[Faculty (Olympus)] 12:40:23
But we started here, AI. Anytime you hear the word AI, think data.

[Faculty (Olympus)] 12:40:29
Which AI am I choosing? What am I solving for?

[Faculty (Olympus)] 12:40:33
My solving for prediction problems, classification problems, machine learning is my thing.

[Faculty (Olympus)] 12:40:39
Okay, do I have structured and labeled data machine learning? Am I solving for more nonlinear problems?

[Faculty (Olympus)] 12:40:47
Deep learning, large volumes of data. Much larger than machine learning.

[Faculty (Olympus)] 12:40:53
Generative AI. Am I looking to generate new content, new music, new book?

[Faculty (Olympus)] 12:40:59
New images generative AI, okay? Then we studied, I cannot emphasize the importance of this data science equals information science plus decision science.

[Faculty (Olympus)] 12:41:13
Information is your models, your data the stats, the maths, the numbers and decisions are the decisions that you will take informed decisions.

[Faculty (Olympus)] 12:41:26
Not rush decisions. Informed decisions using this information.

[Faculty (Olympus)] 12:41:32
With your business stakeholders. Remember, as a data scientist, we act in consulting capacity.

[Faculty (Olympus)] 12:41:40
We act in consulting capacity. Our job is to not only provide a solution.

[Faculty (Olympus)] 12:41:45
Our job is to also educate our business teams Whether or not this is the right solution for them or if this is the right solution for them, then this is how it works in easy terms.

[Faculty (Olympus)] 12:41:58
Without throwing a bunch of fancy terms if A lot of times people think, and I thought so too.

[Faculty (Olympus)] 12:42:05
I thought so too when I was in school for data science that I'm learning coding.

[Faculty (Olympus)] 12:42:09
I'm here to learn Python. So maybe way back then, like about seven, eight years ago, with the without the advent of Gen AI, maybe that was true. Maybe I was learning, but in today's world I challenge you guys to pick up your phones now

[Faculty (Olympus)] 12:42:28
And if you have ChatGPT installed, tell it that I'm trying to train a linear regression model and I'm trying to predict the price of a house generate the data for me.

[Faculty (Olympus)] 12:42:39
And give me the code. It'll do that. It will generate synthetic data for you.

[Faculty (Olympus)] 12:42:45
And it'll say, okay, this is how you code for it.

[Faculty (Olympus)] 12:42:49
So the fact that We are here to learn coding? Yes, that is a means to an end.

[Faculty (Olympus)] 12:42:56
But your real power is how good you explain your code, your solution.

[Faculty (Olympus)] 12:43:04
Your thought process to do your business teams. If you can do that you will be the best, most sought after data scientist in the world.

[Faculty (Olympus)] 12:43:15
If you are a phenomenal coder and you can't explain a thing to people or you can explain things in technical terms only.

[Faculty (Olympus)] 12:43:22
Not as a storyteller. I'll let your businesses decide that for you, right?

[Faculty (Olympus)] 12:43:29
So never underestimate the power studying the landscape of your business okay And then we talked about AI and different real life examples of ai very important here.

[Faculty (Olympus)] 12:43:43
Training data. Spend a good amount of time. How much data do we need? Is the data relevant? Should we collect more data? Is it worth collecting more data?

[Faculty (Olympus)] 12:43:54
If you're cleaning data, how do I address outliers? In tandem with your business. How do I treat missing values in tandem with your business, right?

[Faculty (Olympus)] 12:44:04
And once we've done that, we train a model and then we say, okay, guys, I've got like 95% accuracy. Is it good? I've got 85%.

[Faculty (Olympus)] 12:44:13
Let's study the findings of the model and let's see Should we refine further? Should we stop here?

[Faculty (Olympus)] 12:44:19
Depending on the answer, we studied that we deployed the model And our job doesn't end with model deployment. We continue to monitor the model.

[Faculty (Olympus)] 12:44:29
And we also learned that models have a shelf life. They should have a shelf life.

[Faculty (Olympus)] 12:44:35
If I come to you today. After the session, and I say I'm trying to train a model on my patients train me a model that will work for as long as my hospital runs. Each one of you on this call after this session should tell me no.

[Faculty (Olympus)] 12:44:53
Because a hospital is a dynamic entity with dynamic patient base and ever evolving processes.

[Faculty (Olympus)] 12:44:59
Whatever you're trying to study is bound to change over time. So let's decide what should be the optimal shelf life for this model.

[Faculty (Olympus)] 12:45:09
Then we talked about supervised learning a little bit more in detail.

[Faculty (Olympus)] 12:45:14
And we talked about unsupervised learning. We talked about a little bit reinforcement learning.

[Faculty (Olympus)] 12:45:23
And then we discussed neural networks. And this is where we are.

[Faculty (Olympus)] 12:45:28
Okay, I'm going to quickly pop the chat up.

[Faculty (Olympus)] 12:45:35
Okay, thank you guys. Thank you for your kind feedback. The quiz that's upcoming is… Actually, it's not directly pertaining to the content that we've covered, but it's to give you a flavor of what else is out there and to kind of get you thinking on your feet

[Faculty (Olympus)] 12:45:58
When you hear these different terms, okay? So it's not a quiz on tell me what is discriminative AI And tell me what kind of data do you need for unsupervised learning? No.

[Faculty (Olympus)] 12:46:08
It's not. Put your thinking hats on and let's participate. That's a fun way to end this session.

[Faculty (Olympus)] 12:46:18
So what are the following which of the following are examples of computational paradigm of data science? Before, pause.

[Faculty (Olympus)] 12:46:25
Everyone, before you look at the answer choices. There are two kinds of paradigms, right? Inferential and computational. So inferential is more through statistics well based on what happened i infer that this would happen, right? And computational is you're feeding, it's computing, it's understanding

[Faculty (Olympus)] 12:46:48
And it's giving you some kind of a forecast.

[Faculty (Olympus)] 12:46:51
Okay, so now look at answer choices. There's more than one correct answer here.

[Faculty (Olympus)] 12:47:04
And I trust that you will put in chat b and c

[Faculty (Olympus)] 12:47:12
Okay. E-m-d.

[Faculty (Olympus)] 12:47:21
So there's only two right choices. It can be a b and d okay So the majority of the vote is towards BND.

[Faculty (Olympus)] 12:47:30
Yes, it's BND. So you're computing, right? You're determining, you're forecasting based on historical and weather patterns you're computing.

[Faculty (Olympus)] 12:47:38
For classification. Will it rain or not? Is it going to be windy or not?

[Faculty (Olympus)] 12:47:45
I don't know if any of you is based in Kansas, but I'm based out of Kansas and it's it's super windy like you have to like really use i or at least I am using both my arms to open my car door that's how windy it's been here lately so

[Faculty (Olympus)] 12:47:58
Based on what the weather may have looked like previously in the months of March.

[Faculty (Olympus)] 12:48:04
It's forecasting, it's computing. And optimizing routing of vehicles to minimize the cost. All the FedEx and UPSs are a big utilizer of this optimizing vehicle routes.

[Faculty (Olympus)] 12:48:18
So why are these answers the right answers and others are not?

[Faculty (Olympus)] 12:48:21
So when we talk about weather forecasting, we're using data from vast variety of sources. It's like satellites, weather stations any local radars and then we collect that information and we compute that information.

[Faculty (Olympus)] 12:48:37
To provide accurate forecast. Similarly, for vehicle optimization of the routes, we take into consideration a large number of factors. We're collecting traffic data, the road conditions data, the jams.

[Faculty (Olympus)] 12:48:50
The hours of the day. Is it school hours. Big city small city well the kind of congestion you would see in the morning hours in New York City or LA may not be what you will see in a city in Kansas.

[Faculty (Olympus)] 12:49:02
Still Morning outward, but may not be. So it's taking a lot of that data in and it's computing it and then it's giving you the most cost effective route. So that is why these are the examples of computational paradigms.

[Faculty (Olympus)] 12:49:19
Okay, next question. I believe this was in one of your pre-work videos.

[Faculty (Olympus)] 12:49:24
In World War II, which group of mathematicians played a crucial role in breaking German encryption codes?

[Faculty (Olympus)] 12:49:34
There's one answer only not to. B, yeah.

[Faculty (Olympus)] 12:49:39
You guys got it this was Looks like everybody did the pre-work By the way, guys, not included in this uh as part of this module but As you guys start this journey, it's intense.

[Faculty (Olympus)] 12:49:55
So please stay on top of your pre-work. Your mentors that will be meeting you in mentored learning sessions, they expect that you have covered those modules now Life is life and it happens to all of us.

[Faculty (Olympus)] 12:50:08
If you have not been able to cover the pre-work before a mentored learning session.

[Faculty (Olympus)] 12:50:15
Please let your mentors know. So that they can adjust their explanation accordingly okay But try to stay on top of things.

[Faculty (Olympus)] 12:50:26
All right. So then we're still on the same question. So yes, the Enigma team oh they use the electromechanical device By German military to encrypt and decrypt secret messages so this was probably one of the very early early use cases of something that can come as close to AI.

[Faculty (Olympus)] 12:50:49
Right. Okay, before I ask you this question.

[Faculty (Olympus)] 12:50:56
If I am going to scroll past If I say the word IBM, what's the next word that comes to your mind?

[Faculty (Olympus)] 12:51:08
I see. Yeah. Watson.

[Faculty (Olympus)] 12:51:13
May I mainframe too? Mostly, yeah. So most of the choices are watson so IBM has synonymized itself with the word Watson to where you say the word By the way, the fact that you guys were able to tell me that answer

[Faculty (Olympus)] 12:51:31
It's a neural network up here. It knows most of the times I've heard the word ibm it's either been followed by mainframe or Watson.

[Faculty (Olympus)] 12:51:44
That's the data that you have been trained on. And that is why you guys were so quickly able to write mainframe or Watson.

[Faculty (Olympus)] 12:51:52
Anything data science. So yes, the answer is Watson, but anything data science is not too far from how UNI operate as human beings.

[Faculty (Olympus)] 12:52:02
Think about natural language processing. Or a large language model, they have learned from how you and I speak.

[Faculty (Olympus)] 12:52:09
We have learned from the words you and I use to communicate.

[Faculty (Olympus)] 12:52:13
Machine learning is learning from learning the jobs that you and I work in, the data that we generate at our jobs, the processes that we are hired to to optimize, right?

[Faculty (Olympus)] 12:52:26
It's not too far from real work. So yes, Watson is the answer. So in 2011, IBM developed an AI system which competed on a quiz show, Jeopardy, and defeated the human champions. And the name of the system was Watson.

[Faculty (Olympus)] 12:52:45
So Watson was an advanced AI system which showcased its ability to understand and process natural languages and provide accurate answers to complex questions.

[Faculty (Olympus)] 12:52:58
Does it mean going back to the point I was making earlier, does it mean that Watson, IBM created a brain and plugged it into Watson?

[Faculty (Olympus)] 12:53:09
It means that the learnings by this this thing was advanced.

[Faculty (Olympus)] 12:53:16
And they learned the language so well that it was able to answer complex questions, right?

[Faculty (Olympus)] 12:53:25
Okay. Which of the following are examples of cloud computing services?

[Faculty (Olympus)] 12:53:31
So this is the future of data warehousing and storage. Cloud computing.

[Faculty (Olympus)] 12:53:40
And the unanimous decision. Good job, guys. A and C. So Amazon Web Services.

[Faculty (Olympus)] 12:53:46
So this is where everybody is heading or almost all big companies are heading.

[Faculty (Olympus)] 12:53:52
Is the cloud computing, the value of that is less storage. So I remember when I used to work in hospitals about like 10 years ago, there used to be these big rooms that only certain people could access. That's where IT used to sit. And they had rooms and rooms of servers.

[Faculty (Olympus)] 12:54:08
And they were temperature controlled. And guess what? All of that is going away because of the cloud cloud storage, cloud computing, such as Amazon Web Services and Microsoft Azure, Snowflake.

[Faculty (Olympus)] 12:54:23
Where you pay on demand you can uh let's say you you're running a special project and you have more You need more storage so you pay more storage you scale up and then the project concluded. When we were in traditional systems.

[Faculty (Olympus)] 12:54:38
We would still have those large rooms with large servers one time like capital expenditure, but you're stuck with it.

[Faculty (Olympus)] 12:54:45
But with cloud, of course, you can say, okay, I'm done. I don't have to pay for as much compute or storage resources and then That saves you a lot of money, right?

[Faculty (Olympus)] 12:54:58
Hadoop is the system which most of the companies were using. My company.

[Faculty (Olympus)] 12:55:04
All of the companies that I worked with pretty much worked pretty much have based their data leaks on Hadoop. And what Hadoop was that it was distributed processing and storage of large data set across clusters of computer right But a lot of companies now are keeping Hadoop as well. They have use cases for that. And then they're also bringing in cloud.

[Faculty (Olympus)] 12:55:30
Storage and cloud computing. And then some companies were completely doing away with clustered storage and they say, we want to do 100% migration to to cloud which is a very heavy task because think about it Any Power BI Tableau users here on the call today?

[Faculty (Olympus)] 12:55:54
Nobody? You guys are smart you guys are smart Okay, some tableau. Okay, cool.

[Faculty (Olympus)] 12:56:04
Yeah, so think about you have like 200,000.

[Faculty (Olympus)] 12:56:10
Power BI reports in your company. Sitting on a data lake that is based on dupe and based on Your company is bringing in plug.

[Faculty (Olympus)] 12:56:25
What happens to these 200,000 Power BIs and tableaus and nine workflows and you name it.

[Faculty (Olympus)] 12:56:33
There is a cost to pay here, right? So yes, while you were querying the data set from your data lake, whatever that might be called in your company.

[Faculty (Olympus)] 12:56:43
But if you have to migrate a lot of junk has to be retired.

[Faculty (Olympus)] 12:56:49
You don't want to bring in all 300,000, 300,000 analytical products over to your cloud storage.

[Faculty (Olympus)] 12:56:57
So that's another benefit, a side benefit that when companies are migrating, they're taking a stock of everything that in the past time continued to exist without any oversight.

[Faculty (Olympus)] 12:57:10
Let that be tableaus or knives or Power BIs. But now as they're making these migrations to Snowflake or whatever the case might be.

[Faculty (Olympus)] 12:57:18
They are taking a stock of their inventories. They're saying, do we need to migrate all of this?

[Faculty (Olympus)] 12:57:24
What classifies adjunct classifies as junk And what classifies as good enough to migrate.

[Faculty (Olympus)] 12:57:33
So just some industry example i thought i'll share. All right, so we have three minutes.

[Faculty (Olympus)] 12:57:38
How is edge computing beneficial? So edge computing if for those who don't know.

[Faculty (Olympus)] 12:57:48
It's processing it's processing getting capturing the data at the source and processing, storing it at the source.

[Faculty (Olympus)] 12:57:56
What do you guys think is the answer?

[Faculty (Olympus)] 12:58:04
Network latency centralizes data storage, okay?

[Faculty (Olympus)] 12:58:12
Everyone know what edge computing is?

[Faculty (Olympus)] 12:58:18
So edge means being at the edge So it's collecting data at the source. Okay, so Erica think about older people.

[Faculty (Olympus)] 12:58:32
Who are at a high risk of fall or stroke.

[Faculty (Olympus)] 12:58:37
Which one would you prefer, Erica? To have a sensor attached to a wrist or any part of your body is where If your loved one takes a fall the system gets notified right away versus your loved one takes a fall, the data gets sent away to a centralized location, gets computed there. There is network latency involved there, right?

[Faculty (Olympus)] 12:59:04
Which one? Erica is laughing. Why are you laughing Edge computing is collecting data at that sensor and storing and alerting alerting the people that somebody has taken a fall, right? Similarly, if Erica Yes, need the data as soon as possible. So if Erica is in a self-driving car.

[Faculty (Olympus)] 12:59:27
And that car comes across like a car a flock of ducks or geese crossing the road.

[Faculty (Olympus)] 12:59:36
You want that decision to be made there in that not the car collects the data, sends it to a server, depending on the speed or the network latency, the server does its thing and sends the information back. Oh, break.

[Faculty (Olympus)] 12:59:50
You're supposed to break. No. So that is what edge computing is, Eric.

[Faculty (Olympus)] 12:59:56
So the answer is The benefits of edge computing is that it reduces the network latency and improves real-time data processing.

[Faculty (Olympus)] 13:00:06
I gave you real life examples such as self-driving cars or health care industry. So those are some of the classic examples, right? It reduces the time it takes for the data to travel back and forth between source And a centralized data center

[Faculty (Olympus)] 13:00:22
So that decisions can be made there and that.

[Faculty (Olympus)] 13:00:26
All right, guys, we're almost to the end. If somebody has to hop off Please note that the recording will be available to you.

[Faculty (Olympus)] 13:00:35
So which of the following statements is not a feature of blockchain?

[Faculty (Olympus)] 13:00:45
What is blockchain? Is everybody familiar with blockchain?

[Faculty (Olympus)] 13:00:53
Okay, Ken. Thank you. All right.

[Faculty (Olympus)] 13:01:01
So blockchain is let's go to the answers. So that will help me explain it better.

[Faculty (Olympus)] 13:01:07
So blockchain is the opposite of centralization. It's decentralization. So it doesn't store data like a bank would do. Like if you have an account with like Equity Bank, Bank of America or Sunflower Bank, whichever bank you might be using, it's a very centralized thing, right?

[Faculty (Olympus)] 13:01:25
All the data goes through their central units your transactions and everything, your credit card, whatnot.

[Faculty (Olympus)] 13:01:33
Blockchain removes the big boss. It says nobody's the big boss.

[Faculty (Olympus)] 13:01:39
Data will remain decentralized And it will be stored in these different ledgers Each ledger will be unchangeable.

[Faculty (Olympus)] 13:01:50
Which means it will be immutable. Once a record is stored, nobody can change it.

[Faculty (Olympus)] 13:02:01
It will be secure and it will be transparent. So what does transparency mean?

[Faculty (Olympus)] 13:02:06
Transparency means that if you if you go to a physician, for example, right? He takes your health history and your health records some places it's called EHR, electronic health records and other places called EMR, electronic medical records But it takes your history and let's say you saw a physician in New York and then you're visiting Nebraska

[Faculty (Olympus)] 13:02:31
And you run into an accident, God forbid. And now you have to rush to the ER in Nebraska. The ER physician on call in Nebraska can pull your medical history from whatever happened in New York at your physician's office, right? So that is decentralized.

[Faculty (Olympus)] 13:02:49
He cannot change that health history, but he's also transparent through that.

[Faculty (Olympus)] 13:02:55
Self-signing contracts are a great example of this. Somebody sends you a contract, you sign the contract, the person sending you the contract might be sitting somewhere in Washington and they send you a contract and you guys are sitting, all of you at your locations and you sign the contract.

[Faculty (Olympus)] 13:03:11
Your electronic signatures can be seen by you. By him, nobody can change once you have signed it.

[Faculty (Olympus)] 13:03:17
So that is what blockchain is. And it is the complete opposite of centralization. It's highly decentralized.

[Faculty (Olympus)] 13:03:27
All right so okay come on, guys. This is an easy one. This should be this should be easy Which of the following is a practical example of supervised learning?

[Faculty (Olympus)] 13:03:41
Supervised learning. Structured labeled data.

[Faculty (Olympus)] 13:03:46
Can be used for prediction or classification.

[Faculty (Olympus)] 13:03:54
Okay. Cmd.

[Faculty (Olympus)] 13:04:02
Okay. Cmb.

[Faculty (Olympus)] 13:04:08
Supervised learning So this one, so for those of us who answered A, into different segments. This is unsupervised learning. Remember we talked about clustering?

[Faculty (Olympus)] 13:04:17
So here we are clustering or dividing the customers e-commerce platform could be Amazon, eBay, Etsy any of you Whole Foods, whatever you use to do your transactions online.

[Faculty (Olympus)] 13:04:32
It's clustering or deriding the customers from these platforms into different segments. So that is unsupervised learning, right?

[Faculty (Olympus)] 13:04:39
This is, excuse me guys this is a dimensionality reduction. Again, oops, unsupervised learning.

[Faculty (Olympus)] 13:04:43
You got a high dimensional data. And then you're converting it into lower dimensions. So that is unsupervised learning, dimensionality reduction.

[Faculty (Olympus)] 13:04:53
You've got large volume of data, large variety of data, and you're condensing it to lower dimensions.

[Faculty (Olympus)] 13:04:59
So predicting the price of a car and predicting the likelihood which is classification.

[Faculty (Olympus)] 13:05:06
So prediction, numerical prediction in c And classification.

[Faculty (Olympus)] 13:05:13
Indeed. Will a hotel reservation can get canceled or not?

[Faculty (Olympus)] 13:05:18
So those are supervised learning choices. And then… Which of the following is least likely to be output of a Gen AI model?

[Faculty (Olympus)] 13:05:30
Which one of these is not could not be the output of a gen AI?

[Faculty (Olympus)] 13:05:42
Acmd, CMD. All.

[Faculty (Olympus)] 13:05:49
D. Okay.

[Faculty (Olympus)] 13:05:56
So identifying whether a customer is going to default on a loan payment.

[Faculty (Olympus)] 13:06:00
So it is a yes or no problem. Will somebody pay or not pay? This is a classification problem.

[Faculty (Olympus)] 13:06:06
So this is a supervised learning problem. A portrait of a learning tower in Pisa with artistic features of a yeah these are these are gen ai user journey outputs.

[Faculty (Olympus)] 13:06:21
And that is the end of the session. I will stay here, like I mentioned, to address any outstanding Q&A.

[Faculty (Olympus)] 13:06:31
So today we've learned a high level 30 000 feet view We learned about the history And all of that stuff.

[Faculty (Olympus)] 13:06:41
You guys have more primer sessions coming up. Please sign up for them.

[Faculty (Olympus)] 13:06:46
These are not mandatory sessions. These are optional. But if you attend them, you will only have something to gain and not lose.

[Faculty (Olympus)] 13:06:55
I'm going to stop sharing my screen now and I'm going to pop on For those of you guys who don't have any question, please feel free to hop off.

[Faculty (Olympus)] 13:07:05
I thank you for taking out the time on your Saturday, but I'm going to pop up the Q&A and see if there is something.

[Faculty (Olympus)] 13:07:14
That needs my attention.

[Faculty (Olympus)] 13:07:22
So Adam says, thank you guys. Thank you very much. Adam says, if we want to have AI help identify patterns in data.

[Faculty (Olympus)] 13:07:31
Why wouldn't we want to include as much data as possible to have them find associations So it depends, Adam, what kind of patterns are you trying to identify?

[Faculty (Olympus)] 13:07:44
If I'm trying to predict the price of a house. And one of the variables, let's say in my in my data set is how many years of education this person has had now that doesn't, it's in the data But that doesn't really have a meaningful impact on the price of a house. Now, if I have a variable such as when I say variable, that means features or columns.

[Faculty (Olympus)] 13:08:13
So if I have a variable that says, does the house have a lake?

[Faculty (Olympus)] 13:08:17
At the back. Does the house have a swimming pool? Right?

[Faculty (Olympus)] 13:08:22
Now that is an important variable to include. Ganesh says, how do you actually train a model? The next eight or nine months, Ganesh, is exactly what you will be doing.

[Faculty (Olympus)] 13:08:35
Is learning how to train a model, whether that's a decision tree, a linear regression, logistic regression, a neural network, an SVM.

[Faculty (Olympus)] 13:08:45
Cluster analysis, that's exactly what you have signed up for and paid for. So stay tuned.

[Faculty (Olympus)] 13:08:52
Is the future data same as the test data? I love this question.

[Faculty (Olympus)] 13:08:58
Futures okay so for those of you who are on the call, 45 people are still on the call and Fatma is making an excellent point.

[Faculty (Olympus)] 13:09:05
When you get the data. You will divide it always in two pieces.

[Faculty (Olympus)] 13:09:11
The bulk of it would be used to train the model.

[Faculty (Olympus)] 13:09:17
The splits that we commonly use in the industry are 80-20, So 80% of the data is used for training and 20% of the data is used for tests.

[Faculty (Olympus)] 13:09:28
You will also use 70-30 70% being used for training, 30% for tests.

[Faculty (Olympus)] 13:09:34
The purpose of training data I used to learn from the historical patterns.

[Faculty (Olympus)] 13:09:39
And then the test data is once you make that split, so let's say this is my data set and then I split it And I said, this is training data, right?

[Faculty (Olympus)] 13:09:49
Then this test data, think of it, you put it in a drawer And you've forgotten about it.

[Faculty (Olympus)] 13:09:54
You don't want to know where it is. You don't care where it is.

[Faculty (Olympus)] 13:09:58
You train your model You'll fine tune your model, you improve the predictive performance on this guy. This is your 70% or 80% training data.

[Faculty (Olympus)] 13:10:09
And once you have reached a certain degree of predictive performance, then you bring in that 20% or 10% of your test data and you test it on that.

[Faculty (Olympus)] 13:10:20
It's not the same as future data, Fatma. But what it does is what it does it mimics the future data. It says, oh, okay.

[Faculty (Olympus)] 13:10:28
I see you're giving me a training score of 90% on training data.

[Faculty (Olympus)] 13:10:35
This guy right here. But then let me bring in my test data now.

[Faculty (Olympus)] 13:10:40
On this smaller subset, what is the predictive performance? If I had 90% here and this one is 89% that means My model is not overfitting.

[Faculty (Olympus)] 13:10:52
Overfitting is the number one battle. That you guys will fight as data scientists Whether you're training a neural network or you're doing a decision tree does not matter.

[Faculty (Olympus)] 13:11:03
This is the biggest enemy when we come to train the model.

[Faculty (Olympus)] 13:11:07
If there is a big difference between the training score and the test score, you know Fatma?

[Faculty (Olympus)] 13:11:15
That your model is not ready to be deployed. It's not ready to meet the future data.

[Faculty (Olympus)] 13:11:22
For your training and test score needs to be trending close together.

[Faculty (Olympus)] 13:11:26
If it's 90% in training, your test should be 89%. If there's a big 87%, I'm just throwing numbers that are close enough. It has to be close enough.

[Faculty (Olympus)] 13:11:37
If there's a big gap between training performance and test performance you will not put that model to production.

[Faculty (Olympus)] 13:11:47
Does that make sense, Patna? I hope it does. All right. What is Johnny asks what is a typical final deliverable of a machine learning model for stakeholders her clients so that it can be integrated with other components, apps and dashboards.

[Faculty (Olympus)] 13:12:05
So it depends on the stakeholder or the client. You will integrate it for real-time monitoring and sometimes it will be you doing it and sometimes it will be depending on the landscape of your company You will train the model and then you may hand it off to a separate engineering team. And then you will work in tandem with the engineering team, right?

[Faculty (Olympus)] 13:12:26
You'll work in alliance with the engineering team to continuously monitor could be for drift.

[Faculty (Olympus)] 13:12:32
Could be just for how like the apps and dashboard integration and all of that.

[Faculty (Olympus)] 13:12:38
John says, did you say that columns is features and rows is supervisors No, John. I said, yeah. So when you hear the word columns Some people also call it features and some people also call it variables.

[Faculty (Olympus)] 13:12:56
Okay, so columns equals features equals variables rows equals observations.

[Faculty (Olympus)] 13:13:04
Rose equals the number of instances or I'm not sharing my screen, but going back to the Excel that I showed you earlier, it's the number of rows you have That is the volume of your data.

[Faculty (Olympus)] 13:13:17
The number of columns, also called features. Also called variables is… is the variety of information that you have in your data.

[Faculty (Olympus)] 13:13:30
Okay. Hamansha's question was, are there ways to convert unsupervised learning to supervised learning? So you can do principal component analysis in Manchio. Let's say you got a data set with 80 columns.

[Faculty (Olympus)] 13:13:43
And you did PCA and you said, okay, of these 80 columns for me 12.

[Faculty (Olympus)] 13:13:51
30 or after the PCA are relevant for relevant are meaningful. Then you will take those findings and utilize them in a supervised learning model.

[Faculty (Olympus)] 13:14:03
Okay. And then… Joshua says, can you say unsupervised learning format or Unsupervised learning format or conditions I'm not sure I follow your questions.

[Faculty (Olympus)] 13:14:20
Unsupervised learning format or condition that data for supervised learning. Ah, okay. So I think what I just said, you can use unsupervised learning techniques to refine and consolidate the data so that it can be utilized in supervised learning models. Yes, that can happen.

[Faculty (Olympus)] 13:14:40
Pradeep says, do we need to always classify the structured data with labeled data to proceed with modeling. When you say modeling if you're doing supervised learning yes your labels will supervise what is the right answer and what is the wrong answer.

[Faculty (Olympus)] 13:14:57
So yes, if you're doing Pradeepa, if you have structured data and you have a supervised learning task

